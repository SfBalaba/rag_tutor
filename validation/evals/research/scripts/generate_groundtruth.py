#!/usr/bin/env python
import argparse
import os
import sys
from pathlib import Path

import pandas as pd
from tqdm import tqdm

PROJECT_ROOT = Path(__file__).resolve().parents[3]
EVALS_ROOT = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(EVALS_ROOT))

from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate

from core.config import config
from core.llm import get_llm
from core.ranking import get_doc_content, rerank_documents
from core.vector_store import get_vector_store


def parse_args():
    """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    parser = argparse.ArgumentParser(description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö ground truth –¥–∞–Ω–Ω—ã—Ö")

    parser.add_argument(
        "--questions-csv",
        type=str,
        required=True,
        help="–ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ (–∫–æ–ª–æ–Ω–∫–∞ 'question')",
    )
    parser.add_argument(
        "--output-file",
        type=str,
        default="research/data/synthetic_qa.csv",
        help="–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É CSV —Ñ–∞–π–ª—É",
    )
    parser.add_argument(
        "--num-examples", type=int, default=100, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
    )
    parser.add_argument(
        "--num-chunks", type=int, default=5, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞"
    )
    parser.add_argument(
        "--temperature", type=float, default=0.1, help="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤"
    )

    return parser.parse_args()


def get_relevant_chunks_for_query(vector_store, query: str, n: int = 5):
    """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞"""
    # –ü–æ–ª—É—á–∞–µ–º –±–æ–ª—å—à–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —á–µ–º –Ω—É–∂–Ω–æ –¥–ª—è –ª—É—á—à–µ–≥–æ –æ—Ç–±–æ—Ä–∞
    search_k = min(n * 3, config.get("database", {}).get("search_top_k", 20))
    docs = vector_store.similarity_search(query, k=search_k)

    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ—Ä–∞–Ω–∫–µ—Ä –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
    use_reranker = config.get("reranker", {}).get("enabled", False)
    if use_reranker and docs:
        docs = rerank_documents(query, docs)

    # –ë–µ—Ä–µ–º —Ç–æ–ø-n –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    return docs[:n]


def create_synthetic_dataset(
    questions_df: pd.DataFrame,
    num_examples: int = 100,
    num_chunks: int = 5,
    temperature: float = 0.1,
):
    """–°–æ–∑–¥–∞–µ—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç"""

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    vector_store = get_vector_store()
    llm = get_llm(temperature=temperature)

    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞
    qa_prompt = config.get("qa_prompt", "–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}\n\n–í–æ–ø—Ä–æ—Å: {question}\n\n–û—Ç–≤–µ—Ç:")
    prompt = ChatPromptTemplate.from_template(qa_prompt)

    qa_chain = prompt | llm | StrOutputParser()

    dataset = []

    # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
    if "question" not in questions_df.columns:
        raise ValueError("CSV —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'question'")

    unique_questions = questions_df["question"].dropna().unique()
    questions_to_use = (
        pd.Series(unique_questions)
        .sample(min(len(unique_questions), num_examples), random_state=42)
        .tolist()
    )

    print(f"üìù –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç—ã –¥–ª—è {len(questions_to_use)} –≤–æ–ø—Ä–æ—Å–æ–≤...")

    for question in tqdm(questions_to_use, desc="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞"):
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏
            selected_chunks = get_relevant_chunks_for_query(vector_store, question, num_chunks)

            if not selected_chunks:
                print(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω—ã –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: {question}")
                continue

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            docs_separator = config.get("docs_separator", "\n\n-----")
            context = docs_separator.join(get_doc_content(chunk) for chunk in selected_chunks)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            answer = qa_chain.invoke({"question": question, "context": context})

            dataset.append(
                {
                    "question": question,
                    "answer": answer,
                    "context": context,
                    "num_chunks": len(selected_chunks),
                }
            )

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–æ–ø—Ä–æ—Å–∞ '{question}': {e}")
            continue

    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(dataset)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    return dataset


def validate_dataset(dataset: list):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    if not dataset:
        raise ValueError("–î–∞—Ç–∞—Å–µ—Ç –ø—É—Å—Ç")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
    required_fields = ["question", "answer", "context"]
    for i, item in enumerate(dataset):
        for field in required_fields:
            if field not in item or not item[field].strip():
                print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ø—É—Å—Ç–æ–µ –ø–æ–ª–µ '{field}' –≤ –ø—Ä–∏–º–µ—Ä–µ {i + 1}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    avg_answer_len = sum(len(item["answer"]) for item in dataset) / len(dataset)
    avg_context_len = sum(len(item["context"]) for item in dataset) / len(dataset)

    print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
    print(f"  –ü—Ä–∏–º–µ—Ä–æ–≤: {len(dataset)}")
    print(f"  –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {avg_answer_len:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"  –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {avg_context_len:.0f} —Å–∏–º–≤–æ–ª–æ–≤")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    args = parse_args()

    print("üöÄ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö ground truth –¥–∞–Ω–Ω—ã—Ö")
    print(f"–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {args.questions_csv}")
    print(f"–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {args.output_file}")

    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    os.makedirs(os.path.dirname(args.output_file), exist_ok=True)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏
    if not os.path.exists(args.questions_csv):
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.questions_csv}")

    try:
        questions_df = pd.read_csv(args.questions_csv)
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è CSV —Ñ–∞–π–ª–∞: {e}") from e

    print(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(questions_df)} –∑–∞–ø–∏—Å–µ–π –∏–∑ {args.questions_csv}")

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ rubrics, –∏—Å–∫–ª—é—á–∞–µ–º "–ú–∞—Ç–µ—Ä–∏–∞–ª—ã –∏–∑ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞")
    if "rubrics" in questions_df.columns:
        initial_count = len(questions_df)
        questions_df = questions_df[questions_df["rubrics"] != "–ú–∞—Ç–µ—Ä–∏–∞–ª—ã –∏–∑ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞"]
        filtered_count = len(questions_df)
        if initial_count != filtered_count:
            print(
                f"üîç –ò—Å–∫–ª—é—á–µ–Ω—ã –∑–∞–ø–∏—Å–∏ —Å —Ä—É–±—Ä–∏–∫–æ–π '–ú–∞—Ç–µ—Ä–∏–∞–ª—ã –∏–∑ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞': {initial_count} -> {filtered_count}"
            )

    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    dataset = create_synthetic_dataset(
        questions_df,
        num_examples=args.num_examples,
        num_chunks=args.num_chunks,
        temperature=args.temperature,
    )

    # –í–∞–ª–∏–¥–∞—Ü–∏—è
    validate_dataset(dataset)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    df_output = pd.DataFrame(dataset)
    df_output.to_csv(args.output_file, index=False)

    print(f"‚úÖ –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {args.output_file}")

    # –í—ã–≤–æ–¥–∏–º –ø—Ä–∏–º–µ—Ä—ã
    if len(dataset) > 0:
        print("\nüìù –ü—Ä–∏–º–µ—Ä —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏:")
        example = dataset[0]
        print(f"–í–æ–ø—Ä–æ—Å: {example['question'][:100]}...")
        print(f"–û—Ç–≤–µ—Ç: {example['answer'][:200]}...")


if __name__ == "__main__":
    main()
