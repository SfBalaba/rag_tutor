import os
import re
import shutil
import tempfile
import subprocess
import asyncio
from pathlib import Path
from typing import List, Dict
from tqdm import tqdm

os.environ["TOKENIZERS_PARALLELISM"] = "false"


import nest_asyncio
nest_asyncio.apply()

from llama_parse import LlamaParse

# –ü—É—Ç–∏
DATA_DIR = Path("../data")
FULL_MD_OUTPUT_DIR = Path("../parsed_full")
CHUNKS_OUTPUT_DIR = Path("../parsed_chunks")

LEVELS = ["elementary", "middle_school", "high_school", "university"]

USER_PROMPT = (
    "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–æ–∫—É–º–µ–Ω—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ. –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:\n"
    "1. –°–æ—Ö—Ä–∞–Ω–∏ –ø–æ–ª–Ω—É—é –ª–æ–≥–∏—á–µ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É: –∑–∞–≥–æ–ª–æ–≤–∫–∏, –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–ø–∏—Å–∫–∏, –∞–±–∑–∞—Ü—ã.\n"
    "2. –í—Å–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—É–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–º LaTeX:\n"
    "   - Inline: $...$\n"
    "   - Display: $$...$$\n"
    "3. –¢–∞–±–ª–∏—Ü—ã ‚Äî –≤ —á–∏—Ç–∞–µ–º–æ–º markdown-—Ñ–æ—Ä–º–∞—Ç–µ.\n"
    "4. –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ‚Äî –æ—Ç–º–µ—Ç—å –∫–∞–∫ ![–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ](image_X.png) –∏–ª–∏ <!-- –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: –æ–ø–∏—Å–∞–Ω–∏–µ -->.\n"
    "5. –¢–µ–∫—Å—Ç –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ä—É—Å—Å–∫–∏–π, –ª–∞—Ç–∏–Ω–∏—Ü—É, –≥—Ä–µ—á–µ—Å–∫–∏–µ –±—É–∫–≤—ã, —Ä–∏–º—Å–∫–∏–µ —Ü–∏—Ñ—Ä—ã ‚Äî —Å–æ—Ö—Ä–∞–Ω–∏ –∫–∞–∫ –µ—Å—Ç—å.\n"
    "6. –ù–µ –¥–æ–±–∞–≤–ª—è–π –ø–æ—è—Å–Ω–µ–Ω–∏–π, –ø—Ä–µ–∞–º–±—É–ª –∏–ª–∏ –æ–±—ë—Ä—Ç–æ–∫. –¢–æ–ª—å–∫–æ —á–∏—Å—Ç—ã–π markdown."
)


parser = LlamaParse(
    api_key=userdata.get("LLAMA_CLOUD_API_KEY"),
    result_type="markdown",
    language="ru",
    user_prompt=USER_PROMPT,
    show_progress=False,  # tqdm —Å–∞–º –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å
    ignore_errors=False,
)

# --- –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ ---
async def safe_load_data(file_path: str):
    return await parser.aload_data(file_path)

def parse_with_llamaparse(file_path: str):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ –≤ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ."""
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π loop, –µ—Å–ª–∏ –æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç
        loop = asyncio.get_event_loop()
        if loop.is_closed():
            raise RuntimeError("Loop closed")
        return loop.run_until_complete(safe_load_data(file_path))
    except:
        # –ï—Å–ª–∏ loop —Å–ª–æ–º–∞–Ω ‚Äî —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        result = loop.run_until_complete(safe_load_data(file_path))
        loop.close()
        return result

# --- –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DJVU ---
def convert_djvu_to_pdf(djvu_path: Path) -> Path | None:
    if not shutil.which("ddjvu"):
        print(f"  ‚ö†Ô∏è 'ddjvu' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return None
    try:
        with tempfile.NamedTemporaryFile(suffix=".pdf", delete=False) as tmp:
            tmp_pdf = Path(tmp.name)
        result = subprocess.run(
            ["ddjvu", "-format=pdf", str(djvu_path), str(tmp_pdf)],
            capture_output=True, text=True, timeout=600
        )
        if result.returncode != 0:
            print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ ddjvu: {result.stderr[:200]}")
            tmp_pdf.unlink(missing_ok=True)
            return None
        return tmp_pdf
    except subprocess.TimeoutExpired:
        print(f"  ‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç ddjvu: {djvu_path.name}")
        tmp_pdf.unlink(missing_ok=True)
        return None
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ {djvu_path.name}: {e}")
        return None

# --- –ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ ---
def parse_document(file_path: Path) -> str | None:
    ext = file_path.suffix.lower()
    use_path = file_path

    if ext == ".djvu":
        tmp_pdf = convert_djvu_to_pdf(file_path)
        if tmp_pdf is None:
            return None
        use_path = tmp_pdf
    elif ext != ".pdf":
        return None

    try:
        documents = parse_with_llamaparse(str(use_path))
        if not documents:
            return None
        return "\n\n---\n\n".join([doc.text for doc in documents])
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {file_path.name}: {e}")
        return None
    finally:
        if ext == ".djvu" and use_path != file_path:
            use_path.unlink(missing_ok=True)

# --- –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏ ---
def split_markdown_by_headings(md_text: str) -> List[Dict[str, str]]:
    lines = md_text.split('\n')
    chunks = []
    current_chunk = {"heading": "Document_Start", "content": "", "level": 1}
    heading_pattern = re.compile(r'^(#{1,6})\s+(.*)')

    for line in lines:
        match = heading_pattern.match(line)
        if match:
            if current_chunk["content"].strip() or current_chunk["heading"] != "Document_Start":
                chunks.append(current_chunk.copy())
            level = len(match.group(1))
            heading_text = match.group(2).strip()
            current_chunk = {
                "heading": heading_text,
                "content": line + "\n",
                "level": level
            }
        else:
            current_chunk["content"] += line + "\n"

    if current_chunk["content"].strip():
        chunks.append(current_chunk)
    return chunks

def sanitize_filename(name: str) -> str:
    name = re.sub(r'[^\w\s\-]', '', name.strip())
    name = re.sub(r'\s+', '_', name)
    return name[:100] or "unnamed"

def save_chunks(chunks: List[Dict], output_dir: Path):
    output_dir.mkdir(parents=True, exist_ok=True)
    for i, chunk in enumerate(chunks):
        heading = chunk["heading"]
        fname = f"{i:03d}_{sanitize_filename(heading)}.md"
        with open(output_dir / fname, "w", encoding="utf-8") as f:
            f.write(chunk["content"])

# --- –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª ---
def main():
    print("üöÄ –ù–∞—á–∏–Ω–∞—é –ø–∞—Ä—Å–∏–Ω–≥...")

    for level in LEVELS:
        level_dir = DATA_DIR / level
        if not level_dir.exists():
            continue

        file_paths = []
        for ext in [".pdf", ".djvu"]:
            file_paths.extend(level_dir.rglob(f"*{ext}"))
        file_paths = [f for f in file_paths if f.is_file() and not f.name.startswith(".")]

        if not file_paths:
            continue

        print(f"\nüìÇ –£—Ä–æ–≤–µ–Ω—å: {level} ({len(file_paths)} —Ñ–∞–π–ª–æ–≤)")

        for file_path in tqdm(file_paths, desc=f"  {level}"):
            if "checkpoint" in file_path.name:
                continue

            md_content = parse_document(file_path)
            if md_content is None:
                continue

            rel_path = file_path.relative_to(DATA_DIR)

            full_md_path = FULL_MD_OUTPUT_DIR / rel_path.with_suffix(".md")
            full_md_path.parent.mkdir(parents=True, exist_ok=True)
            with open(full_md_path, "w", encoding="utf-8") as f:
                f.write(md_content)

            chunks = split_markdown_by_headings(md_content)
            chunks_dir = CHUNKS_OUTPUT_DIR / rel_path.parent / rel_path.stem
            save_chunks(chunks, chunks_dir)

            print(f"    ‚úÖ {rel_path.name}")

    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ!")

if __name__ == "__main__":
    main()